"""
Functions related to first time setup.
"""

# Copyright (c) 2017 Platform9 Systems

from urlparse import urlparse
from setupd.common import get_release_version, get_state_data
from setupd.config import Configuration
from setupd.sqlinit import init_metadata_schema
from setupd.util import checked_local_call, write_out_file
from setupd.ecr import get_ecr_login_info
from firkinize.configstore.consul import Consul
from datetime import datetime
from os.path import join as pjoin
import MySQLdb
from multiprocessing import Pool
import os
import yaml
import errno
import logging
import subprocess
import re
import docker
from functools import partial
from uuid import uuid4
try:
    from cStringIO import StringIO
except ImportError:
    from StringIO import StringIO

LOG = logging.getLogger(__name__)

SCHEMA_SQL_FILE = os.path.join(
        os.path.dirname(__file__),
        'base.sql'
        )

HOOKS_DIR = os.path.join(
        os.path.dirname(__file__),
        'hooks')

GRANT_REGEX = re.compile(
    r'^GRANT (?P<permlist>.*?) '
    r'ON (?P<db_name>\S+)\.(?P<table_name>\S+) '
    r'TO (?P<user>\S+)@(?P<host>\S+)'
    r'.*?(?P<grant_option>WITH GRANT OPTION)?$')

SETUPD_ENV_DEFAULTS_FILE = '/etc/setupd-env'

CONTAINER_IMAGES_FILE = '/etc/setupd.images.in'
IMAGE_PUBLISH_FILE = '/etc/setupd.images'


def unescape_sql_str(val):
    """
    Parses out escaped strings from SQL statements.

    'foobar', `foobar` --> foobar

    :type val: str
    :param val: SQL literal value
    :return: unquoted value
    """
    str_delimiters = ["'", "`"]
    for delim in str_delimiters:
        if val[0] == delim and val[-1] == delim:
            return val[1:-1]
    return val


def create_default_db_connection():
    state_data = get_state_data()
    if 'db_host' not in state_data:
        raise Exception('DB hostname missing in state data')
    if 'db_port' not in state_data:
        raise Exception('DB port missing in state data')
    if 'db_user' not in state_data:
        raise Exception('DB username missing in state data')
    if 'db_password' not in state_data:
        raise Exception('DB password missing in state data')
    db = create_and_verify_db_connection(
        state_data['db_host'], int(state_data['db_port']),
        state_data['db_user'], state_data['db_password'])
    db.select_db('pf9_metadata')


def create_and_verify_db_connection(host, port, user, password):
    db = MySQLdb.connect(host=host, port=port, user=user,
                            passwd=password)
    c = db.cursor()
    c.execute('SHOW GRANTS FOR CURRENT_USER')
    priv_tree = {}
    for grant_string, in c.fetchall():
        grant_match = GRANT_REGEX.match(grant_string)
        if not grant_match:
            LOG.warn('Cannot parse grant string (assuming the worst): %s', grant_string)
            continue
        grant_info = grant_match.groupdict()

        perms = [x.strip() for x in grant_info['permlist'].split(',')]
        grant_db_name = unescape_sql_str(grant_info['db_name'])
        grant_table_name = unescape_sql_str(grant_info['table_name'])
        grant_user = unescape_sql_str(grant_info['user'])
        grant_host = unescape_sql_str(grant_info['host'])
        can_subgrant = grant_info.get('grant_option', None) == 'WITH GRANT OPTION'
        if grant_db_name not in priv_tree:
            priv_tree[grant_db_name] = {}
        priv_tree[grant_db_name][grant_table_name] = {
            'perms': perms,
            'can_subgrant': can_subgrant
            }

    if '*' not in priv_tree or '*' not in priv_tree['*']:
        raise Exception('User does not have any global access')

    if 'ALL PRIVILEGES' not in priv_tree['*']['*']['perms']:
        raise Exception('User needs full global privileges')

    if not priv_tree['*']['*']['can_subgrant']:
        raise Exception('User cannot create grants for other users')

    return db


def ensure_metadata_schema(db):
    init_metadata_schema(db)


def get_host_vars(config_data, state_data, admin_password=None, extra_vars={}):
    keystone_db_pass = config_data.passwords['keystone_db_password'].value
    admin_token = config_data.passwords['keystone_admin_token'].value
    cipher_key = config_data.passwords['keystone_cipher_key'].value
    admin_password = admin_password or \
                    config_data.passwords['admin_pass'].value

    host_vars = {
        'customize_env_vars': {
            'DU_FQDN': config_data.fqdn,
            'CUSTOMER_SHORTNAME': config_data.customer.shortname,
            'CUSTOMER_FULLNAME': config_data.customer.fullname,
            'ADMINUSER': config_data.customer.admin_user,
            'ADMINPASS': admin_password,
            'ADMINEMAIL': config_data.customer.admin_user
            },
        'db_host': state_data['db_host'],
        'db_port': state_data.get('db_port', 3306),
        'ext': {
            'account': 'onprem',
            'region': 'onprem'
            },
        'features': {
            name: bool(feat.enabled) for name, feat in \
                config_data.features.items()
            },
        'keystone': {
            'db': {
                'remote_host': state_data['db_host'],
                'port': str(state_data.get('db_port', 3306)),
                'db_name': 'keystone',
                'user': 'keystone',
                'password': str(keystone_db_pass)
                },
            'admin_token': str(admin_token),
            'cipher_key': str(cipher_key)
            },
        'keystone_fqdn': config_data.fqdn,
        'keystone_ip': config_data.fqdn,
        'machine_uuid': config_data.uuid,
        'mysql_user': state_data['db_user'],
        'mysql_password': state_data['db_password'],
        'pf9_create_date': datetime.now().strftime("%Y-%m-%d %H:%M"),
        'pf9_monitoring_ignore': '1',
        'pf9_plan': 'onprem',
        'pf9_version': get_release_version(),
        'region': config_data.region,
        'ui_fqdn': config_data.fqdn,
        'ui_ip': config_data.fqdn
        }

    for password_name, password_data in config_data.passwords.items():
        host_vars[password_name] = password_data.value

    if config_data.has_feature('aws'):
        host_vars['pf9_deployment_type'] = 'aws'
    elif config_data.has_feature('vmw_gateway'):
        host_vars['pf9_deployment_type'] = 'vmware'
    else:
        host_vars['pf9_deployment_type'] = 'kvm'
    host_vars['deployment_type'] = host_vars['pf9_deployment_type']
    host_vars['enabled_neutron'] = config_data.has_feature('enabled_neutron')
    host_vars['aws'] = config_data.has_feature('aws')

    if extra_vars:
        host_vars.update(extra_vars)

    return host_vars


def stage_host_vars(stack_dir, config_data, state_data,
                    admin_password=None, extra_vars={}):
    host_vars = get_host_vars(config_data, state_data,
                              admin_password=admin_password,
                              extra_vars=extra_vars)
    with open(pjoin(stack_dir, 'host_vars', config_data.fqdn), 'w') as f:
        yaml.safe_dump(host_vars, f)


def stage_certificates(stack_dir, config_data):
    base_dir = pjoin(stack_dir, 'roles', 'pf9-configure', 'files',
                     config_data.fqdn, 'etc', 'pf9', 'certs')
    for set_id, set_data in config_data.certificates.items():
        for cert_name, cert_data in set_data.items():
            if set_id == 0:
                cert_dir = pjoin(base_dir, cert_name)
            else:
                cert_dir = pjoin(base_dir, 'v%d' % set_id, cert_name)

            try:
                os.makedirs(cert_dir)
            except OSError as ex: 
                if ex.errno != errno.EEXIST or os.path.isfile(cert_dir):
                    raise

            with open(pjoin(cert_dir, 'cert.pem'), 'wb') as f:
                f.write(cert_data.cert_pem)
            with open(pjoin(cert_dir, 'key.pem'), 'wb') as f:
                f.write(cert_data.private_key_pem)


def create_inventory(stack_dir, config_data):
    inventory_lines = [
        '[onprem_du_prod]',
        '%s ansible_connection=local' % config_data.fqdn
    ]
    with open(pjoin(stack_dir, 'inventory.init'), 'wb') as f:
        f.write('\n'.join(inventory_lines))


def stage_ansible_config_items(stack_dir, config_data, state_data,
                               admin_password=None, extra_vars={}):
    """
    Stages host vars, certificates, and inventory for a given fqdn
    """
    stage_host_vars(stack_dir, config_data, state_data,
                    admin_password=admin_password,
                    extra_vars=extra_vars)
    stage_certificates(stack_dir, config_data)
    create_inventory(stack_dir, config_data)


def populate_db_specs(dbserver_id):
    """
    FIXME: this is lame. We shouldn't hardcode these service names.
    At some point we'll have to come up with a way to choose which
    services to add to a region, and which image version to deploy it from
    based on test results/approvals. For now it's a fixed list of services.
    """
    services = {}
    for service in ['keystone', 'resmgr', 'qbert', 'mysqlfs']:
        services[service] = {'dbserver_key': 'dbservers/%s' % dbserver_id}
    return services


def populate_certs(config):
    """
    Build a dictionary containing certs to be added to consul.
    :type config_data: setupd.config.Configuration
    :param config_data: Configuration dataset
    """
    certs = {}
    if not config.certificates:
        LOG.info('No certificates available, none added to the config store')
    else:
        max_version = max(config.certificates.keys())
        certs['current_version'] = 'v%d' % max_version
        for version, bundle in config.certificates.iteritems():
            strver = 'v%s' % version
            certs[strver] = {}
            for name, cert in bundle.iteritems():
                LOG.info('Adding %s cert for %s', strver, name)
                certs[strver][name] = {
                    'cert': cert.cert_pem,
                    'key': cert.private_key_pem
                }
    return certs


def sync_to_consul(
    config_data,
    state_data,
    keystone_internal_uri='http://localhost:8080/keystone',
    keystone_admin_internal_uri='http://localhost:8080/keystone_admin',
):
    """
    Synchronize all credentials from the database to consul.

    :type config_data: setupd.config.Configuration
    :param config_data: Configuration dataset
    :type state_data: dict
    :param state_data: DU state data
    :param keystone_internal_uri: optional keystone internal URI
    :param keystone_admin_internal_uri: optional keystone_admin internal URI
    :return the consul configuration URL
    """
    consul_url = state_data['consul_url']
    consul = Consul(consul_url)
    dbserver_id = str(uuid4())
    consul_tree = {
        'customers': {
            config_data.customer.uuid: {
                'fqdn': config_data.fqdn,
                'shortname': config_data.customer.shortname,
                'regions': {
                    config_data.uuid: {
                        'region_id': 'RegionOne',
                        'fqdn': config_data.fqdn,
                        'services': populate_db_specs(dbserver_id),
                        'certs': populate_certs(config_data),
                        'rabbit_broker': {
                            'host': 'localhost',
                            'port': 5673,
                            'admin_name': 'admin',
                            'admin_password': config_data.passwords['rabbit_admin_password'].value
                            }
                        },
                    },
                'keystone': {
                    'dbserver_key': 'dbservers/%s' % dbserver_id,
                    'bootstrap': {
                        'email': 'admin@platform9.net',
                        'password': config_data.passwords['admin_keystone_password'].value,
                        'project': 'service',
                        'role': 'admin'
                        },
                    'uris': {
                        'keystone': keystone_internal_uri,
                        'keystone_admin': keystone_admin_internal_uri,
                    },
                    'users': {
                        'service_user': {
                            'email': state_data['admin_user'],
                            'password': state_data['admin_password'],
                            'project': 'service',
                            'role': 'admin'
                            }
                        }
                    }
                }
            },
        'dbservers': {
            dbserver_id: {
                'host': state_data['db_host'],
                'port': state_data.get('db_port', 3306),
                'admin_user': state_data['db_user'],
                'admin_pass': state_data['db_password']
                }
            }
        }

    consul.kv_put_dict(consul_tree)
    return consul_url, dbserver_id


def get_pf9_container_image_names(default_tag, file_location=CONTAINER_IMAGES_FILE):
    """
    Return a list of containers needed to run for any Platform9 services.
    """
    print "looking for the file " + file_location

    image_list = {}
    if os.path.isfile(file_location):
        print "found the file " + file_location
        with open(file_location, 'r') as f:
            image_yaml = yaml.load(f)
            print "file loaded = " 
            for img_name, img_info in image_yaml['images'].iteritems():
                print "image name " + img_name
                if type(img_info) != dict or 'tag' not in img_info:
                    raise Exception('Image info for %s missing tag name' % img_name)
                image_list[img_name] = img_info.copy()
    else:
        image_list = {
            'pf9-forwarder': {'tag': default_tag},
            'pf9-keystone': {'tag': default_tag},
            'pf9-nginx': {'tag': default_tag},
            'pf9-qbert': {'tag': default_tag},
            'pf9-rabbitmq': {'tag': default_tag},
            'pf9-resmgr': {'tag': default_tag},
            'pf9-sidekickserver': {'tag': default_tag},
            'pf9-switcher': {'tag': default_tag},
            }
    print "images loaded = " 
    if 'pf9-qbert' in image_list:
        image_list['pf9-qbert']['options'] = [
            '--privileged',
            '--cap-add=MKNOD',
            '--cap-add=SYS_ADMIN',
            '--device=/dev/fuse'
            ]
    return image_list


def sync_registry(registry_url, default_tag,
                  username=None, password=None,
                  aws_access_key=None, aws_secret_key=None, container_images_file=CONTAINER_IMAGES_FILE):
    """
    Fetches all expected containers from the given docker registry

    :type registry_url: str
    :param registry_url: Docker registry URL
    :type default_tag: str
    :param default_tag: Default tag name to pull for each container, if no setupd.images
                        file is present.
    :type aws_access_key: str
    :param aws_access_key: AWS access key ID (needed if pulling from ECR)
    :type aws_secret_key: str
    :param aws_secret_key: AWS secret key (needed if pulling from ECR)
    """
    if aws_access_key and aws_secret_key:
        username, password = get_ecr_login_info(
                aws_access_key, aws_secret_key, registry_url)

    if username:
        docker_login_args = ['-u', username]
        if password:
            docker_login_args += ['-p', password]
        checked_local_call(['docker', 'login'] + docker_login_args + [registry_url])
    image_list = get_pf9_container_image_names(default_tag, file_location=container_images_file)

    client = docker.from_env(version='auto')
    images = []
    for img_name, img_info in image_list.iteritems():
        img_uri = img_name
        if registry_url:
            img_uri = '%s/%s' % (registry_url, img_name)
        print "pulling image " + img_uri
        try:
            img  = client.images.pull(img_uri, img_info['tag'])
        except Exception as ex:
            print ex.message
        # re-tag the container to strip repository info and keep
        # consistent with the actual image name
        img.tag(img_name, img_info['tag'])
        images.append(img)
    return images


def create_systemd_unit_file(img_name, tag_name, log_dir, options):
    """
    Creates a systemd .service unit file for the given container image that ensures
    the container is running

    :type img_name: str
    :param img_name: container image name
    :type tag_name: str
    :param tag_name: container tag name
    :type log_dir: str
    :param log_dir: path to directory where logs will be sent
    """
    container_opts = ' '.join(options.get('options', []))

    checked_local_call(
        [
            os.path.join(HOOKS_DIR, 'install-container-svc.sh'),
            img_name, tag_name, log_dir, container_opts
        ])


def add_container_services(img_names, log_dir):
    """
    Create service files for each of the containers

    :type img_names: list
    :param img_names: list of container image names
    :type log_dir: str
    :param log_dir: path to directory where logs will be sent
    """
    for img_name, options in img_names.items():
        create_systemd_unit_file(img_name, options['tag'], log_dir, options)


def init_region(consul_url, config_data, log_dir, image_tag_combo):
    """
    Calls init-region for the given container image:tag combo

    :type consul_url: str
    :param consul_url: Consul KV URL
    :type config_data: setupd.config.Configuration
    :param config_data: Configuration class representing customer/region info
    :type log_dir: str
    :param log_dir: path to directory where logs will be sent
    :type image_tag_combo: tuple
    :param image_tag_combo: tuple of (image name, image info) (see `init_regions`)

    :return: True if success, False if not
    :rtype: bool
    """
    img_name, img_info = image_tag_combo

    # use a separate log file for the init-region run
    log_file = os.path.join(log_dir, 'init-region-%s.log' % img_name)
    env = {
        'CONFIG_URL': consul_url,
        'CUSTOMER_ID': config_data.customer.uuid,
        'REGION_ID': config_data.uuid
        }
    init_region_callback = '/root/init-region'
    container_log_dir = os.path.join(log_dir, 'container-%s' % img_name)
    try:
        checked_local_call(['docker', 'run',
            '--network', 'host',
            '-v', '%s:/var/log' % container_log_dir,
            '%s:%s' % (img_name, img_info['tag']),
            init_region_callback,
            '--config-url', consul_url,
            '--customer-id', config_data.customer.uuid,
            '--region-id', config_data.uuid], env=env,
            log_file=log_file)
    except Exception as ex:
        LOG.exception(ex)
        return False

    return True


def init_regions(consul_url, config_data, img_info, log_dir):
    """
    Runs init-regions for each container

    :type consul_url: str
    :param consul_url: Consul KV URL
    :type config_data: setupd.config.Configuration
    :param config_data: Configuration class representing customer/region info
    :type img_info: dict
    :pram img_info: Image information (see `get_pf9_container_image_names`)
    :type log_dir: str
    :param log_dir: path to directory where logs will be sent
    """
    p = Pool(processes=len(img_info.keys()))
    results = p.map(partial(init_region, consul_url, config_data, log_dir),
                    img_info.items())
    if False in results:
        LOG.debug(results)
        LOG.critical('One or more services failed to run init-region')
        raise Exception('init-region failed in one or more services')


def install_and_start_os_dependencies():
    """
    Installs and starts OS-specific dependencies (rabbitmq, consul, etc.)
    """
    LOG.info('Installing OS dependencies')
    checked_local_call(os.path.join(HOOKS_DIR, 'install-os-dependencies.sh'))


def apply_global_environment_file(consul_url, config_data, dest_file):
    """
    Writes out global environment variables for use in all containers

    :type consul_url: str
    :param consul_url: Consul KV URL
    :type config_data: setupd.config.Configuration
    :parma config_data: Customer/Region configuration data class
    :type dest_file: str
    :param dest_file: destination file path
    """
    parsed_url = urlparse(consul_url)
    env_data = """
CONFIG_URL=%(config_url)s
CONFIG_HOST_AND_PORT=%(config_host_and_port)s
CUSTOMER_ID=%(customer_id)s
REGION_ID=%(region_id)s
""" % {
        'config_url': consul_url,
        'config_host_and_port': parsed_url.netloc,
        'customer_id': config_data.customer.uuid,
        'region_id': config_data.uuid
    }
    LOG.info('Writing customer/region ids out to %s', dest_file)
    write_out_file(dest_file, env_data)


def create_container_log_dirs(log_dir, img_names):
    """
    Creates subdirectories for each container to use as a
    bind mount for log directories.

    :type log_dir: str
    :param log_dir: Base log directory
    :type img_names: list
    :param img_names: List of container image names
    """
    for img_name in img_names:
        container_log_dir = os.path.join(log_dir, 'container-%s' % img_name)
        try:
            os.makedirs(container_log_dir)
        except OSError as ex:
            if ex.errno != errno.EEXIST:
                raise


def get_container_image_id(image_name, image_tag):
    """
    Returns the container image id for a given image name and tag combination

    :type image_name: str
    :param image_name: image name
    :type image_tag: str
    :param image_tag: guess

    :rtype: str
    :return: Container image id (usually in the form of "sha256:blahblahblah")
    """
    return checked_local_call(['docker', 'inspect',
        '--format', '{{ .Id }}', '%s:%s' % (image_name, image_tag)]).strip()


def publish_container_image_data(img_names, image_output_file):
    """
    Writes a new YAML file to `image_output_file` containing the
    names, tags, and image hashes of all container images used
    in the deployment.

    :type img_names: dict
    :param img_names: image info (see `get_pf9_container_image_names`)
    :type image_output_file: str
    :param image_output_file: YAML output file
    """
    image_yaml_data = {}
    image_yaml_data['images'] = {}
    for img_name, img_info in img_names.iteritems():
        image_yaml_data['images'][img_name] = {
                'tag': img_info['tag'],
                'id': get_container_image_id(img_name, img_info['tag'])
            }
    with open(image_output_file, 'w') as f:
        yaml.safe_dump(image_yaml_data, stream=f, default_flow_style=False)


def configure_du(config_data, initial_admin_password, db, log_dir, state_data=None):
    state_data = state_data or get_state_data()
    #install_and_start_os_dependencies()
    image_tag = state_data.get('image_tag', 'latest')
    if state_data.get('registry_url', None):
        sync_registry(
            state_data['registry_url'],
            image_tag,
            username=state_data.get('registry_user', None),
            password=state_data.get('registry_password', None),
            aws_access_key=state_data.get('aws_access_key', None),
            aws_secret_key=state_data.get('aws_secret_key', None)
            )
    consul_url, _ = sync_to_consul(config_data, state_data)
    img_names = get_pf9_container_image_names(image_tag)
    create_container_log_dirs(log_dir, img_names.keys())
    init_regions(consul_url, config_data, img_names, log_dir)
    apply_global_environment_file(consul_url, config_data, SETUPD_ENV_DEFAULTS_FILE)
    add_container_services(img_names, log_dir)
    LOG.info('Host configured')
    config_data.phase = 'DEPLOYED'
    config_data.save(db)
    publish_container_image_data(img_names,
            state_data.get('image_publish_file', IMAGE_PUBLISH_FILE))
